{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2431,
     "status": "ok",
     "timestamp": 1580348902162,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "Dsq9tViHdqOR",
    "outputId": "694f7fb3-e875-4cdb-d8a6-2868b2c4237e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow on gpu\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNP14Kam6wYU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig, TFBertModel\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "### custom scripts\n",
    "sys.path.append(\"./utility_scripts/\")\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "from custom_callbacks import EarlyStopping\n",
    "from bert_embedder import compute_input_arrays_tqa, compute_sentece_pair_embedding\n",
    "###\n",
    "\n",
    "MODELS_PATH = \"./models/\" \n",
    "BERT_PATH = \"./transformers/bert-base-uncased/\"\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "SEED = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1APSavGeUg8I"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "af7HHm4OVPoC",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0131 19:53:33.106970 4647570880 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmpe5dy8b0k\n",
      "100%|██████████| 313/313 [00:00<00:00, 68461.47B/s]\n",
      "I0131 19:53:33.761574 4647570880 file_utils.py:309] copying /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmpe5dy8b0k to cache at /Users/martin/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0131 19:53:33.764458 4647570880 file_utils.py:313] creating metadata file for /Users/martin/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0131 19:53:33.772543 4647570880 file_utils.py:322] removing temp file /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmpe5dy8b0k\n",
      "I0131 19:53:33.775802 4647570880 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /Users/martin/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0131 19:53:33.778789 4647570880 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0131 19:53:34.525710 4647570880 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-tf_model.h5 not found in cache or force_download set to True, downloading to /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmp8qcx17as\n",
      "100%|██████████| 536063208/536063208 [00:43<00:00, 12295773.39B/s]\n",
      "I0131 19:54:18.827730 4647570880 file_utils.py:309] copying /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmp8qcx17as to cache at /Users/martin/.cache/torch/transformers/d667df51ec24c20190f01fb4c20a21debc4c4fc12f7e2f5441ac0a99690e3ee9.4733ec82e81d40e9cf5fd04556267d8958fb150e9339390fc64206b7e5a79c83.h5\n",
      "I0131 19:54:22.018208 4647570880 file_utils.py:313] creating metadata file for /Users/martin/.cache/torch/transformers/d667df51ec24c20190f01fb4c20a21debc4c4fc12f7e2f5441ac0a99690e3ee9.4733ec82e81d40e9cf5fd04556267d8958fb150e9339390fc64206b7e5a79c83.h5\n",
      "I0131 19:54:22.020658 4647570880 file_utils.py:322] removing temp file /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmp8qcx17as\n",
      "I0131 19:54:22.094970 4647570880 modeling_tf_utils.py:258] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-tf_model.h5 from cache at /Users/martin/.cache/torch/transformers/d667df51ec24c20190f01fb4c20a21debc4c4fc12f7e2f5441ac0a99690e3ee9.4733ec82e81d40e9cf5fd04556267d8958fb150e9339390fc64206b7e5a79c83.h5\n",
      "I0131 19:54:29.221415 4647570880 configuration_utils.py:71] Configuration saved in ./transformers/bert-base-uncased/config.json\n",
      "I0131 19:54:31.433511 4647570880 modeling_tf_utils.py:138] Model weights saved in ./transformers/bert-base-uncased/tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  bert_base_uncased = TFBertModel.from_pretrained(BERT_PATH) \n",
    "except:\n",
    "  bert_base_uncased = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "  bert_base_uncased.save_pretrained(BERT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4T2wxHSVWGN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0131 19:54:38.104176 4647570880 tokenization_utils.py:306] Model name './transformers/bert-base-uncased/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming './transformers/bert-base-uncased/' is a path or url to a directory containing tokenizer files.\n",
      "I0131 19:54:38.107874 4647570880 tokenization_utils.py:317] Didn't find file ./transformers/bert-base-uncased/vocab.txt. We won't load it.\n",
      "I0131 19:54:38.110166 4647570880 tokenization_utils.py:335] Didn't find file ./transformers/bert-base-uncased/added_tokens.json. We won't load it.\n",
      "I0131 19:54:38.112304 4647570880 tokenization_utils.py:335] Didn't find file ./transformers/bert-base-uncased/special_tokens_map.json. We won't load it.\n",
      "I0131 19:54:38.119630 4647570880 tokenization_utils.py:335] Didn't find file ./transformers/bert-base-uncased/tokenizer_config.json. We won't load it.\n",
      "I0131 19:54:38.850693 4647570880 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmp5m288x8t\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 431800.35B/s]\n",
      "I0131 19:54:40.147556 4647570880 file_utils.py:309] copying /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmp5m288x8t to cache at /Users/martin/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0131 19:54:40.152346 4647570880 file_utils.py:313] creating metadata file for /Users/martin/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0131 19:54:40.155662 4647570880 file_utils.py:322] removing temp file /var/folders/5z/msjn51117gj9gl8xkrrshhqm0000gn/T/tmp5m288x8t\n",
      "I0131 19:54:40.161729 4647570880 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/martin/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  bert_tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n",
    "except:\n",
    "  bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "  bert_tokenizer.save_vocabulary(BERT_PATH)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3lTwvwLVRLM"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BHFT3IkTa35"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\").sample(50).reset_index(drop=True)\n",
    "target_columns = list(train.columns[11:])\n",
    "train_targets = train.loc[:, target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjsY43mqUpD7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 111.18it/s]\n",
      "I0131 19:55:25.474032 4647570880 modeling_tf_utils.py:255] loading weights file ./transformers/bert-base-uncased/tf_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 62s 1s/sample\n"
     ]
    }
   ],
   "source": [
    "train_tqa_bert_encoded = compute_sentece_pair_embedding(train, which=\"tqa\", bert_path=BERT_PATH)\n",
    "train_tqa_bert_encoded.reset_index(inplace=True)\n",
    "bert_columns = train_tqa_bert_encoded.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iog0YW_ze7p9"
   },
   "source": [
    "***\n",
    "## finetuning of the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy1GUPXIabdg"
   },
   "outputs": [],
   "source": [
    "SEED = 19\n",
    "NUM_FOLDS = 5\n",
    "DROPOUT = 0.2\n",
    "ACTIVATION = \"sigmoid\"\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADFBeBGlgGHo"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_xAy_CUgCRf"
   },
   "outputs": [],
   "source": [
    "def get_model(input_size, output_size, activation, dropout):\n",
    "    input_layer = tf.keras.layers.Input((input_size,), dtype=tf.float32, name='input')\n",
    "    input_layer_dpout = tf.keras.layers.Dropout(dropout)(input_layer)\n",
    "    output_layer = tf.keras.layers.Dense(output_size, \n",
    "                                         activation=activation, \n",
    "                                         name=\"output\")(input_layer_dpout)\n",
    "    model = tf.keras.models.Model(inputs=input_layer,\n",
    "                                  outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpVI7RNqgLbA"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137621,
     "status": "ok",
     "timestamp": 1580310775581,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "8nX8xU9YgPdA",
    "outputId": "29428cc2-b5cb-42db-df5c-71e5515314b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################## fold 0 ########################################################\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1865 - valid_spearman_rho: -0.05597412117766229\n",
      "40/40 [==============================] - 1s 14ms/sample - loss: 0.1842 - val_loss: 0.1395\n",
      "Epoch 2/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1440 - valid_spearman_rho: -0.043417349450939974\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1404 - val_loss: 0.1099\n",
      "Epoch 3/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1205 - valid_spearman_rho: -0.03379004361224979\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1152 - val_loss: 0.0888\n",
      "Epoch 4/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/miniconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/martin/miniconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/martin/miniconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/Users/martin/miniconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/Users/martin/miniconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - valid_spearman_rho: -0.052708599482241845\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0976 - val_loss: 0.0747\n",
      "Epoch 5/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0843 - valid_spearman_rho: -0.054079914904539145\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0825 - val_loss: 0.0660\n",
      "Epoch 6/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0736 - valid_spearman_rho: -0.053703939094426174\n",
      "Restoring model weights from the end of the best epoch.\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0731 - val_loss: 0.0610\n",
      "Epoch 00006: early stopping\n",
      "######################################################## fold 1 ########################################################\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.2541 - valid_spearman_rho: -0.13500685065276843\n",
      "40/40 [==============================] - 0s 10ms/sample - loss: 0.2455 - val_loss: 0.1904\n",
      "Epoch 2/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1958 - valid_spearman_rho: -0.1321290910010404\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.1906 - val_loss: 0.1471\n",
      "Epoch 3/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1648 - valid_spearman_rho: -0.130216894194393\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1583 - val_loss: 0.1136\n",
      "Epoch 4/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1275 - valid_spearman_rho: -0.1325816311314407\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1260 - val_loss: 0.0899\n",
      "Epoch 5/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1084 - valid_spearman_rho: -0.13629507524085227\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1062 - val_loss: 0.0742\n",
      "Epoch 6/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0906 - valid_spearman_rho: -0.1302067161427948\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0900 - val_loss: 0.0641\n",
      "Epoch 7/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0832 - valid_spearman_rho: -0.1270886749317736\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0795 - val_loss: 0.0576\n",
      "Epoch 8/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0730 - valid_spearman_rho: -0.12011542067322035\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0721 - val_loss: 0.0536\n",
      "Epoch 9/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0696 - valid_spearman_rho: -0.1002926091283126\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0686 - val_loss: 0.0513\n",
      "Epoch 10/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0650 - valid_spearman_rho: -0.09022105800376307\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0640 - val_loss: 0.0500\n",
      "Epoch 11/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0612 - valid_spearman_rho: -0.08432118385361805\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0623 - val_loss: 0.0493\n",
      "Epoch 12/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0595 - valid_spearman_rho: -0.0778870915709578\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0592 - val_loss: 0.0490\n",
      "Epoch 13/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0602 - valid_spearman_rho: -0.08444809972405608\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0592 - val_loss: 0.0488\n",
      "Epoch 14/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0591 - valid_spearman_rho: -0.09220446440017178\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0592 - val_loss: 0.0486\n",
      "Epoch 15/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0566 - valid_spearman_rho: -0.09298967118835465\n",
      "Restoring model weights from the end of the best epoch.\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0565 - val_loss: 0.0484\n",
      "Epoch 00015: early stopping\n",
      "######################################################## fold 2 ########################################################\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.2312 - valid_spearman_rho: 0.07782641720236232\n",
      "40/40 [==============================] - 0s 12ms/sample - loss: 0.2223 - val_loss: 0.1700\n",
      "Epoch 2/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1823 - valid_spearman_rho: 0.09580025795534705\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1811 - val_loss: 0.1367\n",
      "Epoch 3/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1592 - valid_spearman_rho: 0.10041365083786875\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1551 - val_loss: 0.1109\n",
      "Epoch 4/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1312 - valid_spearman_rho: 0.10475864339642842\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1278 - val_loss: 0.0916\n",
      "Epoch 5/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1082 - valid_spearman_rho: 0.12182113290119183\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1068 - val_loss: 0.0774\n",
      "Epoch 6/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0945 - valid_spearman_rho: 0.12929027072527413\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0927 - val_loss: 0.0673\n",
      "Epoch 7/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0816 - valid_spearman_rho: 0.14515893740651634\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0841 - val_loss: 0.0603\n",
      "Epoch 8/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0761 - valid_spearman_rho: 0.14846800696693063\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0724 - val_loss: 0.0558\n",
      "Epoch 9/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0690 - valid_spearman_rho: 0.14461239199327613\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0684 - val_loss: 0.0531\n",
      "Epoch 10/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0662 - valid_spearman_rho: 0.14350535967224526\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0658 - val_loss: 0.0517\n",
      "Epoch 11/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0622 - valid_spearman_rho: 0.1601935354519714\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0646 - val_loss: 0.0509\n",
      "Epoch 12/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0571 - valid_spearman_rho: 0.1782829062693265\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0600 - val_loss: 0.0503\n",
      "Epoch 13/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0591 - valid_spearman_rho: 0.1894572147883518\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0588 - val_loss: 0.0500\n",
      "Epoch 14/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0590 - valid_spearman_rho: 0.1935452173076834\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0585 - val_loss: 0.0497\n",
      "Epoch 15/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0599 - valid_spearman_rho: 0.19486112069760292\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0586 - val_loss: 0.0496\n",
      "Epoch 16/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0584 - valid_spearman_rho: 0.1930813238643445\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0569 - val_loss: 0.0496\n",
      "Epoch 17/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0585 - valid_spearman_rho: 0.19666052427267164\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0566 - val_loss: 0.0497\n",
      "Epoch 18/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0576 - valid_spearman_rho: 0.19328918345747234\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0564 - val_loss: 0.0497\n",
      "Epoch 19/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0571 - valid_spearman_rho: 0.19237218084087782\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0546 - val_loss: 0.0497\n",
      "Epoch 20/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0534 - valid_spearman_rho: 0.1983953815516344\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0540 - val_loss: 0.0496\n",
      "Epoch 21/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0515 - valid_spearman_rho: 0.1989362475458529\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0543 - val_loss: 0.0493\n",
      "Epoch 22/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0510 - valid_spearman_rho: 0.19676062905909938\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0521 - val_loss: 0.0488\n",
      "Epoch 23/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0534 - valid_spearman_rho: 0.1997477755940519\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0522 - val_loss: 0.0482\n",
      "Epoch 24/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0517 - valid_spearman_rho: 0.2059979369990249\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0519 - val_loss: 0.0478\n",
      "Epoch 25/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0514 - valid_spearman_rho: 0.2070645413609059\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0516 - val_loss: 0.0474\n",
      "Epoch 26/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0534 - valid_spearman_rho: 0.20947663211752804\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0517 - val_loss: 0.0470\n",
      "Epoch 27/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0533 - valid_spearman_rho: 0.2017579848193426\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0522 - val_loss: 0.0467\n",
      "Epoch 28/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0509 - valid_spearman_rho: 0.20355585111924454\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0510 - val_loss: 0.0465\n",
      "Epoch 29/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0506 - valid_spearman_rho: 0.2085191120401109\n",
      "Restoring model weights from the end of the best epoch.\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0494 - val_loss: 0.0463\n",
      "Epoch 00029: early stopping\n",
      "######################################################## fold 3 ########################################################\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.2107 - valid_spearman_rho: 0.1208240867033432\n",
      "40/40 [==============================] - 0s 10ms/sample - loss: 0.2063 - val_loss: 0.1708\n",
      "Epoch 2/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1773 - valid_spearman_rho: 0.1461828769098035\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1707 - val_loss: 0.1385\n",
      "Epoch 3/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1462 - valid_spearman_rho: 0.16382525755962807\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.1384 - val_loss: 0.1138\n",
      "Epoch 4/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1095 - valid_spearman_rho: 0.1713744197834711\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.1086 - val_loss: 0.0961\n",
      "Epoch 5/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0945 - valid_spearman_rho: 0.1852034633460995\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0915 - val_loss: 0.0843\n",
      "Epoch 6/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0798 - valid_spearman_rho: 0.20232123396381305\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0777 - val_loss: 0.0768\n",
      "Epoch 7/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0678 - valid_spearman_rho: 0.20913031306023183\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0677 - val_loss: 0.0722\n",
      "Epoch 8/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0661 - valid_spearman_rho: 0.2102853858218477\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0647 - val_loss: 0.0695\n",
      "Epoch 9/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0583 - valid_spearman_rho: 0.21694344205580063\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0594 - val_loss: 0.0678\n",
      "Epoch 10/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0577 - valid_spearman_rho: 0.2209530607437583\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0597 - val_loss: 0.0666\n",
      "Epoch 11/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0562 - valid_spearman_rho: 0.219596569884713\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0582 - val_loss: 0.0655\n",
      "Epoch 12/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0556 - valid_spearman_rho: 0.2170890236664037\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0557 - val_loss: 0.0645\n",
      "Epoch 13/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0573 - valid_spearman_rho: 0.2298778996239159\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0562 - val_loss: 0.0638\n",
      "Epoch 14/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0567 - valid_spearman_rho: 0.23518146790739677\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0561 - val_loss: 0.0632\n",
      "Epoch 15/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0552 - valid_spearman_rho: 0.23161669563404022\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0543 - val_loss: 0.0628\n",
      "Epoch 16/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0529 - valid_spearman_rho: 0.2286532244877337\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0529 - val_loss: 0.0625\n",
      "Epoch 17/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0512 - valid_spearman_rho: 0.23189913471157764\n",
      "Restoring model weights from the end of the best epoch.\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0522 - val_loss: 0.0622\n",
      "Epoch 00017: early stopping\n",
      "######################################################## fold 4 ########################################################\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.2297 - valid_spearman_rho: -0.08971358409683289\n",
      "40/40 [==============================] - 0s 12ms/sample - loss: 0.2224 - val_loss: 0.1810\n",
      "Epoch 2/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1774 - valid_spearman_rho: -0.07450076201552469\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.1779 - val_loss: 0.1471\n",
      "Epoch 3/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1444 - valid_spearman_rho: -0.05159594418060882\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.1413 - val_loss: 0.1204\n",
      "Epoch 4/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.1125 - valid_spearman_rho: -0.025350825193479753\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.1126 - val_loss: 0.1011\n",
      "Epoch 5/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0951 - valid_spearman_rho: -0.004502870598775341\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0950 - val_loss: 0.0880\n",
      "Epoch 6/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0827 - valid_spearman_rho: 0.005166627713234891\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 7/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0742 - valid_spearman_rho: 0.01940070555606377\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0728 - val_loss: 0.0755\n",
      "Epoch 8/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0628 - valid_spearman_rho: 0.0354087052783889\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0646 - val_loss: 0.0729\n",
      "Epoch 9/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0597 - valid_spearman_rho: 0.05188975183422454\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0612 - val_loss: 0.0713\n",
      "Epoch 10/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0607 - valid_spearman_rho: 0.06414162523823229\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0593 - val_loss: 0.0702\n",
      "Epoch 11/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0568 - valid_spearman_rho: 0.06342925236652398\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0556 - val_loss: 0.0695\n",
      "Epoch 12/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0539 - valid_spearman_rho: 0.06704619222391792\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0557 - val_loss: 0.0689\n",
      "Epoch 13/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0569 - valid_spearman_rho: 0.07104433328043079\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0552 - val_loss: 0.0685\n",
      "Epoch 14/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0516 - valid_spearman_rho: 0.07284576848687235\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0528 - val_loss: 0.0679\n",
      "Epoch 15/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0511 - valid_spearman_rho: 0.08392318185823283\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0526 - val_loss: 0.0672\n",
      "Epoch 16/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0535 - valid_spearman_rho: 0.09163415026822032\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0525 - val_loss: 0.0666\n",
      "Epoch 17/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0526 - valid_spearman_rho: 0.10312461506102795\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0531 - val_loss: 0.0663\n",
      "Epoch 18/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0511 - valid_spearman_rho: 0.10574490181612756\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0506 - val_loss: 0.0661\n",
      "Epoch 19/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0503 - valid_spearman_rho: 0.10702970363227535\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0513 - val_loss: 0.0658\n",
      "Epoch 20/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0509 - valid_spearman_rho: 0.09875484780314986\n",
      "40/40 [==============================] - 0s 3ms/sample - loss: 0.0513 - val_loss: 0.0654\n",
      "Epoch 21/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0534 - valid_spearman_rho: 0.10156700990744351\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0523 - val_loss: 0.0649\n",
      "Epoch 22/100\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 0.0482 - valid_spearman_rho: 0.09588257108304082\n",
      "Restoring model weights from the end of the best epoch.\n",
      "40/40 [==============================] - 0s 2ms/sample - loss: 0.0498 - val_loss: 0.0644\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "kf = MultilabelStratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "kf_split = kf.split(train ,train.loc[:, target_columns])\n",
    "\n",
    "all_models = list()\n",
    "kfold_scores = list()\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf_split):\n",
    "    print(f\" fold {fold} \".center(120, \"#\"))\n",
    "    model = get_model(input_size=768, \n",
    "                      output_size=30,\n",
    "                      activation=ACTIVATION,\n",
    "                      dropout=DROPOUT)\n",
    "        \n",
    "    train_inputs = train_tqa_bert_encoded.loc[train_idx, bert_columns].values\n",
    "    _train_targets = train_targets.loc[train_idx, :].values\n",
    "    \n",
    "    valid_inputs = train_tqa_bert_encoded.loc[valid_idx, bert_columns].values\n",
    "    _valid_targets = train_targets.loc[valid_idx, :].values\n",
    "       \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    callback = EarlyStopping(validation_data=(valid_inputs, _valid_targets),\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             patience=3,\n",
    "                             restore_best_weights=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)\n",
    "    model.fit(train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "              validation_data=(valid_inputs, _valid_targets),\n",
    "              callbacks=[callback])\n",
    "    all_models.append(model)\n",
    "    kfold_scores.append(callback.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-0ycjhNim2A"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1580310776618,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "5_IGrdyjr8sB",
    "outputId": "b7f2632b-adbc-40e4-9195-f2d1b8486505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03379004361224979, -0.0778870915709578, 0.20947663211752804, 0.23518146790739677, 0.10702970363227535]\n",
      "Mean k-fold rho: 0.08800213369479852\n"
     ]
    }
   ],
   "source": [
    "print(kfold_scores)\n",
    "print(f\"Mean k-fold rho: {np.mean(kfold_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fa2kHoyfiotM"
   },
   "outputs": [],
   "source": [
    "for fold,model in enumerate(all_models):\n",
    "    model.save(MODELS_PATH + f\"output_tqa_1h_fold{fold}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1522,
     "status": "ok",
     "timestamp": 1580348950726,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "a9Ml2AkbPSy6",
    "outputId": "b79fe4e3-c5e5-4c60-aaa6-d127118c39a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_tqa_fold0.h5\n",
      "output_tqa_fold1.h5\n",
      "output_tqa_fold2.h5\n",
      "output_tqa_fold3.h5\n",
      "output_tqa_fold4.h5\n"
     ]
    }
   ],
   "source": [
    "# in case the output layers have been precomputed\n",
    "all_models = list()\n",
    "for model_fname in sorted([fname for fname in os.listdir(MODELS_PATH) if \"output_tqa_fold\" in fname]):\n",
    "  print(model_fname)\n",
    "  all_models.append(tf.keras.models.load_model(MODELS_PATH + model_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtGPMNndmWPG"
   },
   "source": [
    "***\n",
    "## finetuning of the bert layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOkUAqFCmTFw"
   },
   "outputs": [],
   "source": [
    "def get_model(output_model, dropout=0.2, output_layer_name=\"output\"):\n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "\n",
    "    config = BertConfig()\n",
    "    bert_layer = TFBertModel.from_pretrained(BERT_PATH, config=config)\n",
    "    hidden_layer,_ = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "\n",
    "    hidden_layer_cls = tf.reshape(hidden_layer[:,0], (-1,768))\n",
    "    \n",
    "    hidden_layer_dpout = tf.keras.layers.Dropout(dropout)(hidden_layer_cls)\n",
    "    output_layer = output_model.get_layer(output_layer_name)(hidden_layer_dpout)\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], \n",
    "        outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2kx--l0pEqj"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtJgJj4LmqVb"
   },
   "outputs": [],
   "source": [
    "SEED = 19\n",
    "NUM_FOLDS = 5\n",
    "DROPOUT = 0.1\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35703,
     "status": "ok",
     "timestamp": 1580349017285,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "LvmiZ_KUqAyA",
    "outputId": "27e23a34-72ce-4fbe-ae41-e019e9021e21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 95.60it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(BERT_PATH+'vocab.txt', True)\n",
    "train_inputs = compute_input_arrays_tqa(train, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pz--1CLvqoV4"
   },
   "source": [
    "***\n",
    "### generates splits for folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yX4Pc71AUJhU"
   },
   "outputs": [],
   "source": [
    "kf = MultilabelStratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "kf_split = kf.split(train ,train.loc[:, target_columns])\n",
    "\n",
    "fold_split = dict()\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf_split):\n",
    "  fold_split[fold] = (train_idx, valid_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hIy2kYIfUoZ3"
   },
   "source": [
    "***\n",
    "### load saved bert models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79iD0S-awLXE"
   },
   "outputs": [],
   "source": [
    "all_bert_models = dict()\n",
    "\n",
    "for model_fname in [fname for fname in os.listdir(MODELS_PATH) if \"bert_tqa\" in fname]:\n",
    "  fold = int(model_fname.split(\"_\")[2][4:])\n",
    "  epoch = int(model_fname.split(\"_\")[3].split(\".\")[0][5:])\n",
    "  all_bert_models[fold] = (tf.keras.models.load_model(MODELS_PATH + model_fname), epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wojbp2gUNZz"
   },
   "source": [
    "***\n",
    "### fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0pd7UO-U6ep"
   },
   "outputs": [],
   "source": [
    "kfold_scores = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3593438,
     "status": "ok",
     "timestamp": 1580352625026,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "8YkWMJ4dbq4i",
    "outputId": "663d21f5-a1b0-4f7e-e13d-1e61cba57197"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0131 20:02:05.051416 4647570880 modeling_tf_utils.py:255] loading weights file ./transformers/bert-base-uncased/tf_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################## fold 0 ########################################################\n",
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0131 20:02:22.832198 4647570880 optimizer_v2.py:1043] Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0131 20:02:31.987792 4647570880 optimizer_v2.py:1043] Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "print(f\" fold {fold} \".center(120, \"#\"))\n",
    "\n",
    "if fold in all_bert_models:\n",
    "  model,epoch = all_bert_models[fold]\n",
    "else:\n",
    "  model = get_model(output_model = all_models[fold],\n",
    "                    dropout = DROPOUT,\n",
    "                    output_layer_name = \"output\")\n",
    "  epoch = 0\n",
    "\n",
    "train_idx,valid_idx = fold_split[fold]\n",
    "\n",
    "_train_inputs = [train_inputs[i][train_idx] for i in range(3)]\n",
    "_train_targets = train_targets.loc[train_idx, :].values\n",
    "\n",
    "_valid_inputs = [train_inputs[i][valid_idx] for i in range(3)]\n",
    "_valid_targets = train_targets.loc[valid_idx, :].values\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "callback = EarlyStopping(validation_data=(_valid_inputs, _valid_targets),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          patience=2,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='max',\n",
    "                          verbose=1)\n",
    "model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "          validation_data=(_valid_inputs, _valid_targets),\n",
    "          callbacks=[callback])\n",
    "all_bert_models[fold] = (model, epoch+EPOCHS)\n",
    "kfold_scores.append(callback.best)\n",
    "model.save(MODELS_PATH + f\"bert_tqa_1h_fold{fold}_epoch{epoch+EPOCHS}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 855,
     "status": "error",
     "timestamp": 1580352626666,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "v-OazWErJfMS",
    "outputId": "18f75569-3f33-4610-e315-e0fd3e2b0ae9"
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8150cc9bc8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"bert_tqa_fold{fold}_epoch{epoch+EPOCHS}.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \"\"\"\n\u001b[1;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1008\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    110\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    111\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 112\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   metadata = dict(\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    167\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1991\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.save(MODELS_PATH + f\"bert_tqa_fold{fold}_epoch{epoch+EPOCHS}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCsEJNqAVgRJ"
   },
   "source": [
    "***\n",
    "### fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 83148,
     "status": "error",
     "timestamp": 1580352709828,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "5MODu_a2VjCA",
    "outputId": "8ee9bbfa-889d-4c03-8a33-00e685a6db0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################## fold 1 ########################################################\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "  12/4863 [..............................] - ETA: 2:37:14 - valid_spearman_rho: 0.3086365662599288\n",
      "  12/4863 [..............................] - ETA: 8:50:53"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1eae6b2d4772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n\u001b[1;32m     29\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_valid_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_valid_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           callbacks=[callback])\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mall_bert_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mkfold_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[12,512,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/tf_bert_model_2/bert/encoder/layer_._11/intermediate/activation/Erf (defined at /usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_bert.py:67) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Reshape_822/_542]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[12,512,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_1/tf_bert_model_2/bert/encoder/layer_._11/intermediate/activation/Erf (defined at /usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_bert.py:67) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_92194]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "print(f\" fold {fold} \".center(120, \"#\"))\n",
    "\n",
    "if fold in all_bert_models:\n",
    "  model,epoch = all_bert_models[fold]\n",
    "else:\n",
    "  model = get_model(output_model = all_models[fold],\n",
    "                    dropout = DROPOUT,\n",
    "                    output_layer_name = \"output\")\n",
    "  epoch = 0\n",
    "\n",
    "train_idx,valid_idx = fold_split[fold]\n",
    "\n",
    "_train_inputs = [train_inputs[i][train_idx] for i in range(3)]\n",
    "_train_targets = train_targets.loc[train_idx, :].values\n",
    "\n",
    "_valid_inputs = [train_inputs[i][valid_idx] for i in range(3)]\n",
    "_valid_targets = train_targets.loc[valid_idx, :].values\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "callback = EarlyStopping(validation_data=(_valid_inputs, _valid_targets),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          patience=2,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='max',\n",
    "                          verbose=1)\n",
    "model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "          validation_data=(_valid_inputs, _valid_targets),\n",
    "          callbacks=[callback])\n",
    "all_bert_models[fold] = (model, epoch+EPOCHS)\n",
    "kfold_scores.append(callback.best)\n",
    "model.save(MODELS_PATH + f\"bert_tqa_fold{fold}_epoch{epoch+EPOCHS}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFciGMt8Vf89"
   },
   "source": [
    "*** \n",
    "### fold 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 83451,
     "status": "error",
     "timestamp": 1580352793295,
     "user": {
      "displayName": "Martín Villanueva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCM2o2iYFEdG2gvf6Mc9uN5ChpVsqatwsVgNWP8Tg=s64",
      "userId": "00273503662431760364"
     },
     "user_tz": 180
    },
    "id": "vcquO96MJwZT",
    "outputId": "e866d74b-ac4f-444b-b5ed-8fc29555f6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################## fold 2 ########################################################\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "  12/4863 [..............................] - ETA: 2:42:51 - valid_spearman_rho: 0.30770025986814714\n",
      "  12/4863 [..............................] - ETA: 8:53:15"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-12bef07f10a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n\u001b[1;32m     29\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_valid_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_valid_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           callbacks=[callback])\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mall_bert_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mkfold_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[12,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_2/tf_bert_model_3/bert/encoder/layer_._10/attention/self/Softmax (defined at /usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_bert.py:242) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Reshape_822/_542]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[12,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_2/tf_bert_model_3/bert/encoder/layer_._10/attention/self/Softmax (defined at /usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_bert.py:242) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_129478]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_2/tf_bert_model_3/bert/encoder/layer_._10/attention/self/Softmax:\n model_2/tf_bert_model_3/bert/encoder/layer_._10/attention/self/add (defined at /usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_bert.py:239)\n\nInput Source operations connected to node model_2/tf_bert_model_3/bert/encoder/layer_._10/attention/self/Softmax:\n model_2/tf_bert_model_3/bert/encoder/layer_._10/attention/self/add (defined at /usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_bert.py:239)\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "fold = 2\n",
    "print(f\" fold {fold} \".center(120, \"#\"))\n",
    "\n",
    "if fold in all_bert_models:\n",
    "  model,epoch = all_bert_models[fold]\n",
    "else:\n",
    "  model = get_model(output_model = all_models[fold],\n",
    "                    dropout = DROPOUT,\n",
    "                    output_layer_name = \"output\")\n",
    "  epoch = 0\n",
    "\n",
    "train_idx,valid_idx = fold_split[fold]\n",
    "\n",
    "_train_inputs = [train_inputs[i][train_idx] for i in range(3)]\n",
    "_train_targets = train_targets.loc[train_idx, :].values\n",
    "\n",
    "_valid_inputs = [train_inputs[i][valid_idx] for i in range(3)]\n",
    "_valid_targets = train_targets.loc[valid_idx, :].values\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "callback = EarlyStopping(validation_data=(_valid_inputs, _valid_targets),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          patience=2,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='max',\n",
    "                          verbose=1)\n",
    "model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "          validation_data=(_valid_inputs, _valid_targets),\n",
    "          callbacks=[callback])\n",
    "all_bert_models[fold] = (model, epoch+EPOCHS)\n",
    "kfold_scores.append(callback.best)\n",
    "model.save(MODELS_PATH + f\"bert_tqa_fold{fold}_epoch{epoch+EPOCHS}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_LkmimKdsSK"
   },
   "source": [
    "*** \n",
    "### fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NupCkeCJ5Bn"
   },
   "outputs": [],
   "source": [
    "fold = 3\n",
    "print(f\" fold {fold} \".center(120, \"#\"))\n",
    "\n",
    "if fold in all_bert_models:\n",
    "  model,epoch = all_bert_models[fold]\n",
    "else:\n",
    "  model = get_model(output_model = all_models[fold],\n",
    "                    dropout = DROPOUT,\n",
    "                    output_layer_name = \"output\")\n",
    "  epoch = 0\n",
    "\n",
    "train_idx,valid_idx = fold_split[fold]\n",
    "\n",
    "_train_inputs = [train_inputs[i][train_idx] for i in range(3)]\n",
    "_train_targets = train_targets.loc[train_idx, :].values\n",
    "\n",
    "_valid_inputs = [train_inputs[i][valid_idx] for i in range(3)]\n",
    "_valid_targets = train_targets.loc[valid_idx, :].values\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "callback = EarlyStopping(validation_data=(_valid_inputs, _valid_targets),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          patience=2,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='max',\n",
    "                          verbose=1)\n",
    "model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "          validation_data=(_valid_inputs, _valid_targets),\n",
    "          callbacks=[callback])\n",
    "all_bert_models[fold] = (model, epoch+EPOCHS)\n",
    "kfold_scores.append(callback.best)\n",
    "model.save(MODELS_PATH + f\"bert_tqa_fold{fold}_epoch{epoch+EPOCHS}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFUepdv2QnbC"
   },
   "source": [
    "***\n",
    "### fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g01sM0jbJ7Uq"
   },
   "outputs": [],
   "source": [
    "fold = 4\n",
    "print(f\" fold {fold} \".center(120, \"#\"))\n",
    "\n",
    "if fold in all_bert_models:\n",
    "  model,epoch = all_bert_models[fold]\n",
    "else:\n",
    "  model = get_model(output_model = all_models[fold],\n",
    "                    dropout = DROPOUT,\n",
    "                    output_layer_name = \"output\")\n",
    "  epoch = 0\n",
    "\n",
    "train_idx,valid_idx = fold_split[fold]\n",
    "\n",
    "_train_inputs = [train_inputs[i][train_idx] for i in range(3)]\n",
    "_train_targets = train_targets.loc[train_idx, :].values\n",
    "\n",
    "_valid_inputs = [train_inputs[i][valid_idx] for i in range(3)]\n",
    "_valid_targets = train_targets.loc[valid_idx, :].values\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "callback = EarlyStopping(validation_data=(_valid_inputs, _valid_targets),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          patience=2,\n",
    "                          restore_best_weights=True,\n",
    "                          mode='max',\n",
    "                          verbose=1)\n",
    "model.fit(_train_inputs, _train_targets, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "          validation_data=(_valid_inputs, _valid_targets),\n",
    "          callbacks=[callback])\n",
    "all_bert_models[fold] = (model, epoch+EPOCHS)\n",
    "kfold_scores.append(callback.best)\n",
    "model.save(MODELS_PATH + f\"bert_tqa_fold{fold}_epoch{epoch+EPOCHS}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_vcpf8NRAyv"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szDmj4FtRG7K"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPS6IpbcdsB7e+HGtn626mZ",
   "collapsed_sections": [],
   "name": "BERT finetuning - tqa - 1 hidden layer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
